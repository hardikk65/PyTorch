{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-12T12:30:33.502290Z","iopub.execute_input":"2024-01-12T12:30:33.502892Z","iopub.status.idle":"2024-01-12T12:30:33.511539Z","shell.execute_reply.started":"2024-01-12T12:30:33.502858Z","shell.execute_reply":"2024-01-12T12:30:33.510614Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/cifar10-python/cifar-10-python.tar.gz\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_1\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_2\n/kaggle/input/cifar10-python/cifar-10-batches-py/batches.meta\n/kaggle/input/cifar10-python/cifar-10-batches-py/test_batch\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_3\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_5\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_4\n/kaggle/input/cifar10-python/cifar-10-batches-py/readme.html\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch \nimport torch.nn.functional as F ","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:30:33.513563Z","iopub.execute_input":"2024-01-12T12:30:33.513932Z","iopub.status.idle":"2024-01-12T12:30:33.518982Z","shell.execute_reply.started":"2024-01-12T12:30:33.513901Z","shell.execute_reply":"2024-01-12T12:30:33.518125Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\n\ndef unpickle(file):\n    import pickle\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n\ntrain_batch = {}\ntest_batch = unpickle('/kaggle/input/cifar10-python/cifar-10-batches-py/test_batch')\nfor i in range(5):\n    train_batch[f'batch_{i+1}'] = unpickle(\"/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_%d\"%(i + 1))\n\n\ndef get_dataset(batch_dict,test_dict):\n\n\n    training_image = torch.tensor(torch.cat((torch.tensor(batch_dict['batch_1'][b'data']),torch.tensor(batch_dict['batch_2'][b'data']),torch.tensor(batch_dict['batch_3'][b'data']),torch.tensor(batch_dict['batch_4'][b'data']),torch.tensor(batch_dict['batch_5'][b'data'])),0),dtype = torch.float32)\n    training_labels = torch.tensor(torch.cat((torch.tensor(batch_dict['batch_1'][b'labels']),torch.tensor(batch_dict['batch_2'][b'labels']),torch.tensor(batch_dict['batch_3'][b'labels']),torch.tensor(batch_dict['batch_4'][b'labels']),torch.tensor(batch_dict['batch_5'][b'labels']))))     \n\n    test_images = torch.tensor(test_dict[b'data'],dtype = torch.float32)\n    test_labels = torch.tensor(test_dict[b'labels'])\n\n    training_image = training_image.view(50000,3,32,32)\n    test_images = test_images.view(test_images.shape[0],3,32,32)\n\n    return training_image,training_labels,test_images,test_labels\n\n\ndef make_batches(batch_size=16):\n    training_image,training_labels,test_images,test_labels = get_dataset(train_batch,test_batch)\n    train_dataset = TensorDataset(training_image,training_labels)\n    test_dataset = TensorDataset(test_images,test_labels)\n    train_loader = DataLoader(train_dataset,shuffle=True,batch_size=batch_size)\n    test_loader = DataLoader(test_dataset,shuffle =True,batch_size=batch_size)\n\n    return train_loader,test_loader","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:30:33.520018Z","iopub.execute_input":"2024-01-12T12:30:33.520303Z","iopub.status.idle":"2024-01-12T12:30:35.348475Z","shell.execute_reply.started":"2024-01-12T12:30:33.520281Z","shell.execute_reply":"2024-01-12T12:30:35.347425Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\ndef training(model,criterion,optimizer,train_loader,epochs=10,device='cuda'):\n    training_loss = 0.0\n    training_accuracy = 0\n    for epoch in range(epochs):\n        for i,(images,labels) in enumerate(train_loader):\n            images= images.to(device)\n            labels = labels.to(device)\n            output = model(images)\n\n            loss = criterion(output,labels)\n\n            # training_loss += loss.item()\n            optimizer.zero_grad()\n\n            loss.backward()\n\n            optimizer.step()\n\n            _, predicted = torch.max(output.data, 1)\n\n            training_accuracy += (predicted == labels).sum().item()\n            if ((i+1)%100 == 0):\n                print(f'epoch:{epoch + 1},loss:{loss.item():.4f}')\n        print(f'accuracy:{training_accuracy*100/50000}')\n        training_accuracy = 0    \n\n#     torch.save(model.state_dict(),'/kaggle/working/model.pth')\n\n    return model\n\n\ndef evaluation(model,test_loader,device='cuda'):\n    with torch.no_grad():\n        n_correct = 0\n        n_samples = 0\n        test_loss = 0.0\n        test_accuracy = 0\n        for i,(images, labels) in enumerate(test_loader):\n            images= images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            n_samples += labels.size(0)\n            n_correct += (predicted == labels).sum().item()\n            \n        acc = 100.0 * n_correct / n_samples\n        \n        print(f'Accuracy of the network on the 10000 test images: {acc} %')","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:30:35.351254Z","iopub.execute_input":"2024-01-12T12:30:35.351540Z","iopub.status.idle":"2024-01-12T12:30:35.362274Z","shell.execute_reply.started":"2024-01-12T12:30:35.351515Z","shell.execute_reply":"2024-01-12T12:30:35.361255Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    \n    def __init__(self,input_channels,no_of_filters,kernel_size=3,stride1 = 1,stride2 = 1,padding = 1):\n        \n        super(ResidualBlock,self).__init__()\n        \n        self.resblock = nn.Sequential(nn.Conv2d(input_channels,no_of_filters,kernel_size = kernel_size,stride = stride1,padding = padding),\n                                      nn.BatchNorm2d(no_of_filters),\n                                      nn.ReLU(),\n                                      nn.Conv2d(no_of_filters,no_of_filters,kernel_size = kernel_size,stride = stride2,padding = padding),\n                                      nn.BatchNorm2d(no_of_filters),\n                                      nn.ReLU()\n                                     )\n    def forward(self,x):\n        \n        x = self.resblock(x)\n        return x \n    \n    \nclass IdentityBlock(nn.Module):\n    \n        def __init__(self,input_channels,no_of_filters,kernel_size=3,stride = 1 ,padding = 0):\n            \n            super(IdentityBlock,self).__init__()\n            \n            self.idblock = nn.Sequential(nn.Conv2d(input_channels,no_of_filters,kernel_size = kernel_size,stride = stride,padding = padding),\n                                          nn.BatchNorm2d(no_of_filters),\n                                          nn.ReLU()\n                                         )\n        def forward(self,x):\n        \n            x = self.idblock(x)\n            return x ","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:31:27.143487Z","iopub.execute_input":"2024-01-12T12:31:27.144350Z","iopub.status.idle":"2024-01-12T12:31:27.153340Z","shell.execute_reply.started":"2024-01-12T12:31:27.144316Z","shell.execute_reply":"2024-01-12T12:31:27.152425Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Resnet32(nn.Module):\n    \n    def __init__(self):\n        super(Resnet32,self).__init__()\n        \n        self.block1_0 = nn.Conv2d(3,64,3,padding = 1) \n        \n        self.block1_1 = ResidualBlock(64,64,kernel_size = 3)                                             \n        self.block1_2 = ResidualBlock(64,64,kernel_size = 3)\n        self.block1_3 = ResidualBlock(64,64,kernel_size = 3)\n        \n        self.block2_0 = IdentityBlock(64,128,kernel_size =1 ,stride =2)                  \n        self.block2_1 = ResidualBlock(64,128,stride1=2,stride2=1)                                                \n        \n        self.block3_0 = ResidualBlock(128,128,stride1=1,stride2=1)\n        self.block3_1 = ResidualBlock(128,128,stride1=1,stride2=1)\n        self.block3_2 = ResidualBlock(128,128,stride1=1,stride2=1)\n        \n        self.block4_0 = IdentityBlock(128,256,kernel_size =1 ,stride =2)\n        self.block4_1 = ResidualBlock(128,256,stride1=2,stride2=1)\n\n        self.block5_0 = ResidualBlock(256,256,stride1=1,stride2=1)\n        self.block5_1 = ResidualBlock(256,256,stride1=1,stride2=1)\n        self.block5_2 = ResidualBlock(256,256,stride1=1,stride2=1)\n        self.block5_3 = ResidualBlock(256,256,stride1=1,stride2=1)\n        self.block5_4 = ResidualBlock(256,256,stride1=1,stride2=1)\n        \n        self.block6_0 = IdentityBlock(256,512,kernel_size =1 ,stride =2)\n        self.block6_1 = ResidualBlock(256,512,stride1=2,stride2=1)\n        \n        self.block7_0 = ResidualBlock(512,512,stride1=1,stride2=1)\n        self.block7_1 = ResidualBlock(512,512,stride1=1,stride2=1)\n        \n        self.fc1 = nn.Linear(512*4*4,512)\n        self.fc2 = nn.Linear(512,10)\n        \n        self.bnorm = nn.BatchNorm1d(512)\n\n        \n        \n    def forward(self,x):\n        \n        x = self.block1_0(x)\n        \n        shortcut = x\n        x = self.block1_1(x)\n        x = x + shortcut\n        \n        shortcut = x\n        x = self.block1_2(x)\n        x = x + shortcut\n            \n        shortcut = x\n        x = self.block1_3(x)\n        x = x + shortcut\n\n        \n        shortcut = x\n        x = self.block2_1(x)\n        shortcut = self.block2_0(shortcut) \n        x = x + shortcut\n\n        \n        shortcut = x \n        x = self.block3_0(x)\n        x = x + shortcut\n        \n        shortcut = x \n        x = self.block3_1(x)\n        x = x + shortcut\n        \n        shortcut = x \n        x = self.block3_2(x)\n        x = x + shortcut\n        \n        \n        \n        shortcut = x\n        shortcut = self.block4_0(shortcut)\n        x = self.block4_1(x)\n        x = x + shortcut\n\n\n\n        shortcut = x \n        x = self.block5_0(x)\n        x = x + shortcut\n        \n        shortcut = x \n        x = self.block5_1(x)\n        x = x + shortcut\n        \n        shortcut = x \n        x = self.block5_2(x)\n        x = x + shortcut\n        \n\n        shortcut = x \n        x = self.block5_3(x)\n        x = x + shortcut\n        \n        shortcut = x \n        x = self.block5_4(x)\n        x = x + shortcut\n\n        shortcut = x\n        shortcut = self.block6_0(shortcut)\n        x = self.block6_1(x)\n        x = x + shortcut\n        \n        shortcut = x \n        x = self.block7_0(x)\n        x = x + shortcut\n        \n        shortcut = x \n        x = self.block7_1(x)\n        x = x + shortcut\n        \n        \n        x = x.view(x.shape[0],512*4*4)\n        \n        x = self.fc1(x)\n        x = F.relu(self.bnorm(x))\n        \n        x = self.fc2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:32:22.557360Z","iopub.execute_input":"2024-01-12T12:32:22.557907Z","iopub.status.idle":"2024-01-12T12:32:22.584882Z","shell.execute_reply.started":"2024-01-12T12:32:22.557862Z","shell.execute_reply":"2024-01-12T12:32:22.583125Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"resnet = Resnet32()","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:32:23.207927Z","iopub.execute_input":"2024-01-12T12:32:23.208308Z","iopub.status.idle":"2024-01-12T12:32:23.393572Z","shell.execute_reply.started":"2024-01-12T12:32:23.208279Z","shell.execute_reply":"2024-01-12T12:32:23.392786Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"device = 'cuda'\nresnet.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:32:23.685048Z","iopub.execute_input":"2024-01-12T12:32:23.685410Z","iopub.status.idle":"2024-01-12T12:32:23.881437Z","shell.execute_reply.started":"2024-01-12T12:32:23.685381Z","shell.execute_reply":"2024-01-12T12:32:23.880572Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Resnet32(\n  (block1_0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (block1_1): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block1_2): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block1_3): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block2_0): IdentityBlock(\n    (idblock): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n    )\n  )\n  (block2_1): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block3_0): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block3_1): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block3_2): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block4_0): IdentityBlock(\n    (idblock): Sequential(\n      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n    )\n  )\n  (block4_1): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block5_0): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block5_1): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block5_2): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block5_3): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block5_4): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block6_0): IdentityBlock(\n    (idblock): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n    )\n  )\n  (block6_1): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block7_0): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (block7_1): ResidualBlock(\n    (resblock): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    )\n  )\n  (fc1): Linear(in_features=8192, out_features=512, bias=True)\n  (fc2): Linear(in_features=512, out_features=10, bias=True)\n  (bnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"train_loader,test_loader = make_batches(128)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:32:27.997191Z","iopub.execute_input":"2024-01-12T12:32:27.997544Z","iopub.status.idle":"2024-01-12T12:32:28.404000Z","shell.execute_reply.started":"2024-01-12T12:32:27.997516Z","shell.execute_reply":"2024-01-12T12:32:28.403031Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_26/53764489.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  training_image = torch.tensor(torch.cat((torch.tensor(batch_dict['batch_1'][b'data']),torch.tensor(batch_dict['batch_2'][b'data']),torch.tensor(batch_dict['batch_3'][b'data']),torch.tensor(batch_dict['batch_4'][b'data']),torch.tensor(batch_dict['batch_5'][b'data'])),0),dtype = torch.float32)\n/tmp/ipykernel_26/53764489.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  training_labels = torch.tensor(torch.cat((torch.tensor(batch_dict['batch_1'][b'labels']),torch.tensor(batch_dict['batch_2'][b'labels']),torch.tensor(batch_dict['batch_3'][b'labels']),torch.tensor(batch_dict['batch_4'][b'labels']),torch.tensor(batch_dict['batch_5'][b'labels']))))\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(resnet.parameters(),lr = 0.001)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:32:29.170720Z","iopub.execute_input":"2024-01-12T12:32:29.171451Z","iopub.status.idle":"2024-01-12T12:32:29.176729Z","shell.execute_reply.started":"2024-01-12T12:32:29.171422Z","shell.execute_reply":"2024-01-12T12:32:29.175841Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"new_model =  training(resnet,criterion,optimizer,train_loader,epochs = 15)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:32:30.601181Z","iopub.execute_input":"2024-01-12T12:32:30.602003Z","iopub.status.idle":"2024-01-12T12:43:09.759876Z","shell.execute_reply.started":"2024-01-12T12:32:30.601970Z","shell.execute_reply":"2024-01-12T12:43:09.758936Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"epoch:1,loss:1.5379\nepoch:1,loss:1.2984\nepoch:1,loss:1.1724\naccuracy:50.304\nepoch:2,loss:0.9863\nepoch:2,loss:0.7923\nepoch:2,loss:0.6749\naccuracy:70.902\nepoch:3,loss:0.5341\nepoch:3,loss:0.5723\nepoch:3,loss:0.6286\naccuracy:79.222\nepoch:4,loss:0.5458\nepoch:4,loss:0.5242\nepoch:4,loss:0.5037\naccuracy:84.256\nepoch:5,loss:0.3389\nepoch:5,loss:0.2311\nepoch:5,loss:0.4087\naccuracy:88.56\nepoch:6,loss:0.1586\nepoch:6,loss:0.2052\nepoch:6,loss:0.2786\naccuracy:92.374\nepoch:7,loss:0.1078\nepoch:7,loss:0.1210\nepoch:7,loss:0.1871\naccuracy:94.806\nepoch:8,loss:0.0634\nepoch:8,loss:0.0705\nepoch:8,loss:0.1010\naccuracy:96.258\nepoch:9,loss:0.0490\nepoch:9,loss:0.0615\nepoch:9,loss:0.0726\naccuracy:97.456\nepoch:10,loss:0.1197\nepoch:10,loss:0.0185\nepoch:10,loss:0.1188\naccuracy:97.938\nepoch:11,loss:0.0695\nepoch:11,loss:0.1090\nepoch:11,loss:0.0496\naccuracy:97.968\nepoch:12,loss:0.0122\nepoch:12,loss:0.0837\nepoch:12,loss:0.0422\naccuracy:98.186\nepoch:13,loss:0.0258\nepoch:13,loss:0.0359\nepoch:13,loss:0.0393\naccuracy:98.302\nepoch:14,loss:0.0233\nepoch:14,loss:0.0231\nepoch:14,loss:0.0342\naccuracy:98.866\nepoch:15,loss:0.0169\nepoch:15,loss:0.0182\nepoch:15,loss:0.0423\naccuracy:98.65\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluation(resnet,test_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:43:09.761804Z","iopub.execute_input":"2024-01-12T12:43:09.762464Z","iopub.status.idle":"2024-01-12T12:43:12.956119Z","shell.execute_reply.started":"2024-01-12T12:43:09.762428Z","shell.execute_reply":"2024-01-12T12:43:12.955185Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Accuracy of the network on the 10000 test images: 82.93 %\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}