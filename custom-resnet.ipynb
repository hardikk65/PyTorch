{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-12T12:50:25.407136Z","iopub.execute_input":"2024-01-12T12:50:25.407553Z","iopub.status.idle":"2024-01-12T12:50:25.425865Z","shell.execute_reply.started":"2024-01-12T12:50:25.407518Z","shell.execute_reply":"2024-01-12T12:50:25.424776Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/cifar10-python/cifar-10-python.tar.gz\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_1\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_2\n/kaggle/input/cifar10-python/cifar-10-batches-py/batches.meta\n/kaggle/input/cifar10-python/cifar-10-batches-py/test_batch\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_3\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_5\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_4\n/kaggle/input/cifar10-python/cifar-10-batches-py/readme.html\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch \nimport torch.nn.functional as F ","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:50:25.427847Z","iopub.execute_input":"2024-01-12T12:50:25.428726Z","iopub.status.idle":"2024-01-12T12:50:25.433659Z","shell.execute_reply.started":"2024-01-12T12:50:25.428687Z","shell.execute_reply":"2024-01-12T12:50:25.432637Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\n\ndef unpickle(file):\n    import pickle\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n\ntrain_batch = {}\ntest_batch = unpickle('/kaggle/input/cifar10-python/cifar-10-batches-py/test_batch')\nfor i in range(5):\n    train_batch[f'batch_{i+1}'] = unpickle(\"/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_%d\"%(i + 1))\n\n\ndef get_dataset(batch_dict,test_dict):\n\n\n    training_image = torch.tensor(torch.cat((torch.tensor(batch_dict['batch_1'][b'data']),torch.tensor(batch_dict['batch_2'][b'data']),torch.tensor(batch_dict['batch_3'][b'data']),torch.tensor(batch_dict['batch_4'][b'data']),torch.tensor(batch_dict['batch_5'][b'data'])),0),dtype = torch.float32)\n    training_labels = torch.tensor(torch.cat((torch.tensor(batch_dict['batch_1'][b'labels']),torch.tensor(batch_dict['batch_2'][b'labels']),torch.tensor(batch_dict['batch_3'][b'labels']),torch.tensor(batch_dict['batch_4'][b'labels']),torch.tensor(batch_dict['batch_5'][b'labels']))))     \n\n    test_images = torch.tensor(test_dict[b'data'],dtype = torch.float32)\n    test_labels = torch.tensor(test_dict[b'labels'])\n\n    training_image = training_image.view(50000,3,32,32)\n    test_images = test_images.view(test_images.shape[0],3,32,32)\n\n    return training_image,training_labels,test_images,test_labels\n\n\ndef make_batches(batch_size=16):\n    training_image,training_labels,test_images,test_labels = get_dataset(train_batch,test_batch)\n    train_dataset = TensorDataset(training_image,training_labels)\n    test_dataset = TensorDataset(test_images,test_labels)\n    train_loader = DataLoader(train_dataset,shuffle=True,batch_size=batch_size)\n    test_loader = DataLoader(test_dataset,shuffle =True,batch_size=batch_size)\n\n    return train_loader,test_loader","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:50:25.434833Z","iopub.execute_input":"2024-01-12T12:50:25.435165Z","iopub.status.idle":"2024-01-12T12:50:27.302850Z","shell.execute_reply.started":"2024-01-12T12:50:25.435139Z","shell.execute_reply":"2024-01-12T12:50:27.301834Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\ndef training(model,criterion,optimizer,train_loader,epochs=10,device='cuda'):\n    training_loss = 0.0\n    training_accuracy = 0\n    for epoch in range(epochs):\n        for i,(images,labels) in enumerate(train_loader):\n            images= images.to(device)\n            labels = labels.to(device)\n            output = model(images)\n\n            loss = criterion(output,labels)\n\n            # training_loss += loss.item()\n            optimizer.zero_grad()\n\n            loss.backward()\n\n            optimizer.step()\n\n            _, predicted = torch.max(output.data, 1)\n\n            training_accuracy += (predicted == labels).sum().item()\n            if ((i+1)%100 == 0):\n                print(f'epoch:{epoch + 1},loss:{loss.item():.4f}')\n        print(f'accuracy:{training_accuracy*100/50000}')\n        training_accuracy = 0    \n\n#     torch.save(model.state_dict(),'/kaggle/working/model.pth')\n\n    return model\n\n\ndef evaluation(model,test_loader,device='cuda'):\n    with torch.no_grad():\n        n_correct = 0\n        n_samples = 0\n        test_loss = 0.0\n        test_accuracy = 0\n        for i,(images, labels) in enumerate(test_loader):\n            images= images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            n_samples += labels.size(0)\n            n_correct += (predicted == labels).sum().item()\n            \n        acc = 100.0 * n_correct / n_samples\n        \n        print(f'Accuracy of the network on the 10000 test images: {acc} %')","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:50:27.305446Z","iopub.execute_input":"2024-01-12T12:50:27.305790Z","iopub.status.idle":"2024-01-12T12:50:27.317188Z","shell.execute_reply.started":"2024-01-12T12:50:27.305764Z","shell.execute_reply":"2024-01-12T12:50:27.316105Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Resnet(nn.Module):\n\n  def __init__ (self):\n\n    super(Resnet,self).__init__()\n\n    self.pad = nn.ZeroPad2d(2)\n\n    self.Conv0 = nn.Conv2d(3,64,3,padding=1)\n    self.Conv1 = nn.Conv2d(64,64,3,padding=1)\n    self.Conv2 = nn.Conv2d(64,128,3,padding=1)\n    self.Conv3 = nn.Conv2d(128,128,3,padding=1)\n    self.Conv4 = nn.Conv2d(128,256,3,padding=1)\n    self.Conv5 = nn.Conv2d(256,256,3,padding=1)\n    self.Conv6 = nn.Conv2d(256,512,3,padding=1)\n    self.Conv7 = nn.Conv2d(512,512,3,padding=1)\n    self.maxpool = nn.MaxPool2d(2)\n\n    self.bnorm1 = nn.BatchNorm2d(64)\n    self.bnorm2 = nn.BatchNorm2d(128)\n    self.bnorm3 = nn.BatchNorm2d(256)\n    self.bnorm4 = nn.BatchNorm2d(512)\n\n    self.avgpool = nn.AvgPool2d(2)\n\n    self.Linear1 = nn.Linear(512*2*2,512)\n    self.Linear2 = nn.Linear(512,10)\n\n    self.softmax = nn.Softmax(1)\n\n\n  def forward(self,x) :\n\n     x = self.Conv0(x)\n\n     shortcut = x\n\n     x = F.relu(self.Conv1(x))\n     x = F.relu(self.bnorm1(self.Conv1(x)))\n     x = x + shortcut\n\n     shortcut = x\n\n     x = F.relu(self.Conv1(x))\n     x = F.relu(self.bnorm1(self.Conv1(x)))\n     x = x + shortcut\n\n     shortcut = F.relu(self.bnorm2(self.Conv2(x)))\n     shortcut = self.maxpool(shortcut)\n\n     x = F.relu(self.bnorm2(self.Conv2(x)))\n     x = F.relu(self.bnorm2(self.Conv3(x)))\n     x = self.maxpool(x)\n     x = x + shortcut\n\n     shortcut = x\n\n     x = F.relu(self.bnorm2(self.Conv3(x)))\n     x = F.relu(self.bnorm2(self.Conv3(x)))\n     x = x + shortcut\n\n     shortcut = F.relu(self.bnorm3(self.Conv4(x)))\n     shortcut = self.maxpool(shortcut)\n\n     x = F.relu(self.bnorm3(self.Conv4(x)))\n     x = F.relu(self.bnorm3(self.Conv5(x)))\n     x = self.maxpool(x)\n     x = x + shortcut\n\n     shortcut = x\n\n     x = F.relu(self.bnorm3(self.Conv5(x)))\n     x = F.relu(self.bnorm3(self.Conv5(x)))\n     x = x + shortcut\n\n     shortcut = F.relu(self.bnorm4(self.Conv6(x)))\n     shortcut = self.maxpool(shortcut)\n\n     x = F.relu(self.bnorm4(self.Conv6(x)))\n     x = F.relu(self.bnorm4(self.Conv7(x)))\n     x = self.maxpool(x)\n     x = x + shortcut\n\n     shortcut = x\n\n     x = F.relu(self.bnorm4(self.Conv7(x)))\n     x = F.relu(self.bnorm4(self.Conv7(x)))\n     x = x + shortcut\n\n\n     x = self.avgpool(x)\n\n     x = x.view(x.shape[0],512*2*2)\n     x = F.relu(self.Linear1(x))\n\n     x = self.Linear2(x)\n    #  x = self.softmax(x)\n\n\n     return x\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:50:27.318392Z","iopub.execute_input":"2024-01-12T12:50:27.318699Z","iopub.status.idle":"2024-01-12T12:50:27.340976Z","shell.execute_reply.started":"2024-01-12T12:50:27.318675Z","shell.execute_reply":"2024-01-12T12:50:27.339977Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"resnet = Resnet()","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:50:27.342074Z","iopub.execute_input":"2024-01-12T12:50:27.342347Z","iopub.status.idle":"2024-01-12T12:50:27.426869Z","shell.execute_reply.started":"2024-01-12T12:50:27.342324Z","shell.execute_reply":"2024-01-12T12:50:27.426070Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device = 'cuda'\nresnet.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:50:27.428058Z","iopub.execute_input":"2024-01-12T12:50:27.428354Z","iopub.status.idle":"2024-01-12T12:50:27.616000Z","shell.execute_reply.started":"2024-01-12T12:50:27.428329Z","shell.execute_reply":"2024-01-12T12:50:27.615063Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Resnet(\n  (pad): ZeroPad2d((2, 2, 2, 2))\n  (Conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (Conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (Conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (Conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (Conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (Conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (Conv6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (Conv7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (bnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (bnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (bnorm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (bnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (Linear1): Linear(in_features=2048, out_features=512, bias=True)\n  (Linear2): Linear(in_features=512, out_features=10, bias=True)\n  (softmax): Softmax(dim=1)\n)"},"metadata":{}}]},{"cell_type":"code","source":"train_loader,test_loader = make_batches(128)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:50:27.617263Z","iopub.execute_input":"2024-01-12T12:50:27.617661Z","iopub.status.idle":"2024-01-12T12:50:28.027282Z","shell.execute_reply.started":"2024-01-12T12:50:27.617621Z","shell.execute_reply":"2024-01-12T12:50:28.026301Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_25/53764489.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  training_image = torch.tensor(torch.cat((torch.tensor(batch_dict['batch_1'][b'data']),torch.tensor(batch_dict['batch_2'][b'data']),torch.tensor(batch_dict['batch_3'][b'data']),torch.tensor(batch_dict['batch_4'][b'data']),torch.tensor(batch_dict['batch_5'][b'data'])),0),dtype = torch.float32)\n/tmp/ipykernel_25/53764489.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  training_labels = torch.tensor(torch.cat((torch.tensor(batch_dict['batch_1'][b'labels']),torch.tensor(batch_dict['batch_2'][b'labels']),torch.tensor(batch_dict['batch_3'][b'labels']),torch.tensor(batch_dict['batch_4'][b'labels']),torch.tensor(batch_dict['batch_5'][b'labels']))))\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(resnet.parameters(),lr = 0.001)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:50:28.028479Z","iopub.execute_input":"2024-01-12T12:50:28.028885Z","iopub.status.idle":"2024-01-12T12:50:28.034021Z","shell.execute_reply.started":"2024-01-12T12:50:28.028848Z","shell.execute_reply":"2024-01-12T12:50:28.033018Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"new_model =  training(resnet,criterion,optimizer,train_loader,epochs = 15)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:50:28.037136Z","iopub.execute_input":"2024-01-12T12:50:28.037797Z","iopub.status.idle":"2024-01-12T13:00:15.179761Z","shell.execute_reply.started":"2024-01-12T12:50:28.037762Z","shell.execute_reply":"2024-01-12T13:00:15.178807Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"epoch:1,loss:1.7580\nepoch:1,loss:1.7694\nepoch:1,loss:1.4976\naccuracy:35.298\nepoch:2,loss:1.1806\nepoch:2,loss:1.0136\nepoch:2,loss:1.0096\naccuracy:60.976\nepoch:3,loss:0.7609\nepoch:3,loss:1.0184\nepoch:3,loss:0.7242\naccuracy:72.35\nepoch:4,loss:0.6300\nepoch:4,loss:0.5452\nepoch:4,loss:0.6822\naccuracy:78.494\nepoch:5,loss:0.6107\nepoch:5,loss:0.7032\nepoch:5,loss:0.5154\naccuracy:82.508\nepoch:6,loss:0.4169\nepoch:6,loss:0.4798\nepoch:6,loss:0.4068\naccuracy:85.446\nepoch:7,loss:0.3701\nepoch:7,loss:0.3757\nepoch:7,loss:0.2792\naccuracy:88.256\nepoch:8,loss:0.3544\nepoch:8,loss:0.2853\nepoch:8,loss:0.2996\naccuracy:89.824\nepoch:9,loss:0.1817\nepoch:9,loss:0.2402\nepoch:9,loss:0.2097\naccuracy:91.902\nepoch:10,loss:0.2561\nepoch:10,loss:0.1679\nepoch:10,loss:0.1333\naccuracy:93.274\nepoch:11,loss:0.2046\nepoch:11,loss:0.2217\nepoch:11,loss:0.1701\naccuracy:94.552\nepoch:12,loss:0.1000\nepoch:12,loss:0.1390\nepoch:12,loss:0.1255\naccuracy:95.798\nepoch:13,loss:0.0602\nepoch:13,loss:0.1062\nepoch:13,loss:0.0681\naccuracy:96.298\nepoch:14,loss:0.0929\nepoch:14,loss:0.0486\nepoch:14,loss:0.0799\naccuracy:96.99\nepoch:15,loss:0.0282\nepoch:15,loss:0.1176\nepoch:15,loss:0.0347\naccuracy:97.498\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluation(resnet,test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T13:00:15.181488Z","iopub.execute_input":"2024-01-12T13:00:15.181783Z","iopub.status.idle":"2024-01-12T13:00:18.174664Z","shell.execute_reply.started":"2024-01-12T13:00:15.181760Z","shell.execute_reply":"2024-01-12T13:00:18.173732Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Accuracy of the network on the 10000 test images: 87.07 %\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}