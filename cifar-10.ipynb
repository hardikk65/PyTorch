{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d733c9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:20.975095Z",
     "iopub.status.busy": "2024-01-12T12:00:20.974332Z",
     "iopub.status.idle": "2024-01-12T12:00:21.824560Z",
     "shell.execute_reply": "2024-01-12T12:00:21.823129Z"
    },
    "papermill": {
     "duration": 0.864247,
     "end_time": "2024-01-12T12:00:21.827259",
     "exception": false,
     "start_time": "2024-01-12T12:00:20.963012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cifar10/data_batch_1\n",
      "/kaggle/input/cifar10/data_batch_2\n",
      "/kaggle/input/cifar10/batches.meta\n",
      "/kaggle/input/cifar10/test_batch\n",
      "/kaggle/input/cifar10/data_batch_3\n",
      "/kaggle/input/cifar10/data_batch_5\n",
      "/kaggle/input/cifar10/data_batch_4\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d7cd01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:21.845277Z",
     "iopub.status.busy": "2024-01-12T12:00:21.844762Z",
     "iopub.status.idle": "2024-01-12T12:00:25.312934Z",
     "shell.execute_reply": "2024-01-12T12:00:25.311933Z"
    },
    "papermill": {
     "duration": 3.479886,
     "end_time": "2024-01-12T12:00:25.315431",
     "exception": false,
     "start_time": "2024-01-12T12:00:21.835545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56b2ce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:25.328614Z",
     "iopub.status.busy": "2024-01-12T12:00:25.327753Z",
     "iopub.status.idle": "2024-01-12T12:00:25.650259Z",
     "shell.execute_reply": "2024-01-12T12:00:25.649283Z"
    },
    "papermill": {
     "duration": 0.331615,
     "end_time": "2024-01-12T12:00:25.652723",
     "exception": false,
     "start_time": "2024-01-12T12:00:25.321108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b1e3dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:25.665436Z",
     "iopub.status.busy": "2024-01-12T12:00:25.664825Z",
     "iopub.status.idle": "2024-01-12T12:00:25.668918Z",
     "shell.execute_reply": "2024-01-12T12:00:25.668129Z"
    },
    "papermill": {
     "duration": 0.012444,
     "end_time": "2024-01-12T12:00:25.670838",
     "exception": false,
     "start_time": "2024-01-12T12:00:25.658394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "948fa769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:25.682852Z",
     "iopub.status.busy": "2024-01-12T12:00:25.682209Z",
     "iopub.status.idle": "2024-01-12T12:00:27.719682Z",
     "shell.execute_reply": "2024-01-12T12:00:27.718832Z"
    },
    "papermill": {
     "duration": 2.045933,
     "end_time": "2024-01-12T12:00:27.722017",
     "exception": false,
     "start_time": "2024-01-12T12:00:25.676084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "\n",
    "train_batch = {}\n",
    "test_batch = unpickle('/kaggle/input/cifar10/test_batch')\n",
    "for i in range(5):\n",
    "    train_batch[f'batch_{i+1}'] = unpickle(\"/kaggle/input/cifar10/data_batch_%d\"%(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3ecc1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:27.734778Z",
     "iopub.status.busy": "2024-01-12T12:00:27.734427Z",
     "iopub.status.idle": "2024-01-12T12:00:27.745994Z",
     "shell.execute_reply": "2024-01-12T12:00:27.745188Z"
    },
    "papermill": {
     "duration": 0.020263,
     "end_time": "2024-01-12T12:00:27.747967",
     "exception": false,
     "start_time": "2024-01-12T12:00:27.727704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(batch_dict,test_dict):\n",
    "\n",
    "\n",
    "    training_image = torch.tensor(torch.cat((torch.tensor(batch_dict['batch_1'][b'data']),torch.tensor(batch_dict['batch_2'][b'data']),torch.tensor(batch_dict['batch_3'][b'data']),torch.tensor(batch_dict['batch_4'][b'data']),torch.tensor(batch_dict['batch_5'][b'data'])),0),dtype = torch.float32)\n",
    "    training_labels = torch.tensor(torch.cat((torch.tensor(batch_dict['batch_1'][b'labels']),torch.tensor(batch_dict['batch_2'][b'labels']),torch.tensor(batch_dict['batch_3'][b'labels']),torch.tensor(batch_dict['batch_4'][b'labels']),torch.tensor(batch_dict['batch_5'][b'labels']))))     \n",
    "\n",
    "    test_images = torch.tensor(test_dict[b'data'],dtype = torch.float32)\n",
    "    test_labels = torch.tensor(test_dict[b'labels'])\n",
    "\n",
    "    training_image = training_image.view(50000,3,32,32)\n",
    "    test_images = test_images.view(test_images.shape[0],3,32,32)\n",
    "\n",
    "    return training_image,training_labels,test_images,test_labels\n",
    "\n",
    "\n",
    "def make_batches(batch_size=16):\n",
    "    training_image,training_labels,test_images,test_labels = get_dataset(train_batch,test_batch)\n",
    "    train_dataset = TensorDataset(training_image,training_labels)\n",
    "    test_dataset = TensorDataset(test_images,test_labels)\n",
    "    train_loader = DataLoader(train_dataset,shuffle=True,batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset,shuffle =True,batch_size=batch_size)\n",
    "\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63efe3a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:27.762061Z",
     "iopub.status.busy": "2024-01-12T12:00:27.761378Z",
     "iopub.status.idle": "2024-01-12T12:00:27.769087Z",
     "shell.execute_reply": "2024-01-12T12:00:27.768217Z"
    },
    "papermill": {
     "duration": 0.017655,
     "end_time": "2024-01-12T12:00:27.771221",
     "exception": false,
     "start_time": "2024-01-12T12:00:27.753566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def training(model,criterion,optimizer,train_loader,epochs=10):\n",
    "    training_loss = 0.0\n",
    "    training_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i,(images,labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            loss = criterion(output,labels)\n",
    "\n",
    "            # training_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "            training_accuracy += (predicted == labels).sum().item()\n",
    "            if ((i+1)%100 == 0):\n",
    "                print(f'epoch:{epoch + 1},loss:{loss.item():.4f}')\n",
    "        print(f'accuracy:{training_accuracy*100/50000}')\n",
    "        training_accuracy = 0    \n",
    "\n",
    "#     torch.save('Network/model.pth',model.state_dict())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778b15e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:27.784399Z",
     "iopub.status.busy": "2024-01-12T12:00:27.784039Z",
     "iopub.status.idle": "2024-01-12T12:00:27.790981Z",
     "shell.execute_reply": "2024-01-12T12:00:27.790142Z"
    },
    "papermill": {
     "duration": 0.015828,
     "end_time": "2024-01-12T12:00:27.793026",
     "exception": false,
     "start_time": "2024-01-12T12:00:27.777198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluation(model,test_loader):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        test_loss = 0.0\n",
    "        test_accuracy = 0\n",
    "        for i,(images, labels) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e831d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:27.805857Z",
     "iopub.status.busy": "2024-01-12T12:00:27.805528Z",
     "iopub.status.idle": "2024-01-12T12:00:28.593936Z",
     "shell.execute_reply": "2024-01-12T12:00:28.592893Z"
    },
    "papermill": {
     "duration": 0.797657,
     "end_time": "2024-01-12T12:00:28.596446",
     "exception": false,
     "start_time": "2024-01-12T12:00:27.798789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/3786781395.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  training_image = torch.tensor(torch.cat((torch.tensor(batch_dict['batch_1'][b'data']),torch.tensor(batch_dict['batch_2'][b'data']),torch.tensor(batch_dict['batch_3'][b'data']),torch.tensor(batch_dict['batch_4'][b'data']),torch.tensor(batch_dict['batch_5'][b'data'])),0),dtype = torch.float32)\n",
      "/tmp/ipykernel_27/3786781395.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  training_labels = torch.tensor(torch.cat((torch.tensor(batch_dict['batch_1'][b'labels']),torch.tensor(batch_dict['batch_2'][b'labels']),torch.tensor(batch_dict['batch_3'][b'labels']),torch.tensor(batch_dict['batch_4'][b'labels']),torch.tensor(batch_dict['batch_5'][b'labels']))))\n"
     ]
    }
   ],
   "source": [
    "train_loader,_ = make_batches(128)\n",
    "_,test_loader = make_batches(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa79e330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:28.609325Z",
     "iopub.status.busy": "2024-01-12T12:00:28.608973Z",
     "iopub.status.idle": "2024-01-12T12:00:28.615952Z",
     "shell.execute_reply": "2024-01-12T12:00:28.615117Z"
    },
    "papermill": {
     "duration": 0.015555,
     "end_time": "2024-01-12T12:00:28.617821",
     "exception": false,
     "start_time": "2024-01-12T12:00:28.602266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvBN(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_channels,filters,strides = 1,kernel_size = 3,padding = 1,rate = 0.25,drop = False):\n",
    "        super(ConvBN,self).__init__()\n",
    "        self.drop = drop\n",
    "        self.conv = nn.Conv2d(input_channels,filters,kernel_size = kernel_size,padding = padding,stride = strides)\n",
    "        self.bnorm = nn.BatchNorm2d(filters)\n",
    "#         self.dropout = nn.dropout(rate)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        output = self.conv(inputs)\n",
    "        \n",
    "        output = F.relu(self.bnorm(output))\n",
    "        \n",
    "#         if self.drop:\n",
    "#             output = self.droupout(output)\n",
    "            \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c53162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:28.630582Z",
     "iopub.status.busy": "2024-01-12T12:00:28.630230Z",
     "iopub.status.idle": "2024-01-12T12:00:28.642867Z",
     "shell.execute_reply": "2024-01-12T12:00:28.641981Z"
    },
    "papermill": {
     "duration": 0.021257,
     "end_time": "2024-01-12T12:00:28.644809",
     "exception": false,
     "start_time": "2024-01-12T12:00:28.623552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(VGG16,self).__init__()\n",
    "        \n",
    "        self.conv1 = ConvBN(3,64)\n",
    "        self.conv2 = ConvBN(64,64)\n",
    "        \n",
    "        self.conv3 = ConvBN(64,128)\n",
    "        self.conv4 = ConvBN(128,128)\n",
    "        \n",
    "        self.conv5 = ConvBN(128,256)\n",
    "        self.conv6 = ConvBN(256,256)\n",
    "        self.conv7 = ConvBN(256,256)\n",
    "        \n",
    "        self.conv8 = ConvBN(256,512)\n",
    "        self.conv9 = ConvBN(512,512)\n",
    "        self.conv10 = ConvBN(512,512)\n",
    "        \n",
    "        self.conv11 = ConvBN(512,512)\n",
    "        self.conv12 = ConvBN(512,512)\n",
    "        self.conv13 = ConvBN(512,512)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(512,512)\n",
    "        self.fc2 = nn.Linear(512,10)\n",
    "    \n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "        self.batchnorm = nn.BatchNorm1d(512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(self.conv2(x))\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool(self.conv4(x))\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.maxpool(self.conv7(x))\n",
    "        \n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.maxpool(self.conv10(x))\n",
    "        \n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.maxpool(self.conv13(x))\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = x.view(x.shape[0],512*1*1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        x = self.batchnorm(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b2d8d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:28.657210Z",
     "iopub.status.busy": "2024-01-12T12:00:28.656880Z",
     "iopub.status.idle": "2024-01-12T12:00:28.774748Z",
     "shell.execute_reply": "2024-01-12T12:00:28.773738Z"
    },
    "papermill": {
     "duration": 0.1267,
     "end_time": "2024-01-12T12:00:28.777183",
     "exception": false,
     "start_time": "2024-01-12T12:00:28.650483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d0d476a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:28.790450Z",
     "iopub.status.busy": "2024-01-12T12:00:28.790064Z",
     "iopub.status.idle": "2024-01-12T12:00:28.794436Z",
     "shell.execute_reply": "2024-01-12T12:00:28.793443Z"
    },
    "papermill": {
     "duration": 0.013409,
     "end_time": "2024-01-12T12:00:28.796598",
     "exception": false,
     "start_time": "2024-01-12T12:00:28.783189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device= 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "936930e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:28.809415Z",
     "iopub.status.busy": "2024-01-12T12:00:28.809068Z",
     "iopub.status.idle": "2024-01-12T12:00:29.028732Z",
     "shell.execute_reply": "2024-01-12T12:00:29.027786Z"
    },
    "papermill": {
     "duration": 0.228511,
     "end_time": "2024-01-12T12:00:29.030972",
     "exception": false,
     "start_time": "2024-01-12T12:00:28.802461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16(\n",
       "  (conv1): ConvBN(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): ConvBN(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): ConvBN(\n",
       "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv4): ConvBN(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv5): ConvBN(\n",
       "    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv6): ConvBN(\n",
       "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv7): ConvBN(\n",
       "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv8): ConvBN(\n",
       "    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv9): ConvBN(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv10): ConvBN(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv11): ConvBN(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv12): ConvBN(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv13): ConvBN(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1138c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:29.044050Z",
     "iopub.status.busy": "2024-01-12T12:00:29.043752Z",
     "iopub.status.idle": "2024-01-12T12:00:29.048636Z",
     "shell.execute_reply": "2024-01-12T12:00:29.047865Z"
    },
    "papermill": {
     "duration": 0.013871,
     "end_time": "2024-01-12T12:00:29.050633",
     "exception": false,
     "start_time": "2024-01-12T12:00:29.036762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "898eec57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:00:29.064100Z",
     "iopub.status.busy": "2024-01-12T12:00:29.063823Z",
     "iopub.status.idle": "2024-01-12T12:03:50.243205Z",
     "shell.execute_reply": "2024-01-12T12:03:50.241969Z"
    },
    "papermill": {
     "duration": 201.189202,
     "end_time": "2024-01-12T12:03:50.245600",
     "exception": false,
     "start_time": "2024-01-12T12:00:29.056398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1,loss:1.8135\n",
      "epoch:1,loss:1.6363\n",
      "epoch:1,loss:1.5103\n",
      "accuracy:35.178\n",
      "epoch:2,loss:1.1336\n",
      "epoch:2,loss:0.9601\n",
      "epoch:2,loss:0.9183\n",
      "accuracy:62.776\n",
      "epoch:3,loss:0.6517\n",
      "epoch:3,loss:0.8039\n",
      "epoch:3,loss:0.8106\n",
      "accuracy:74.16\n",
      "epoch:4,loss:0.6506\n",
      "epoch:4,loss:0.6319\n",
      "epoch:4,loss:0.5263\n",
      "accuracy:79.834\n",
      "epoch:5,loss:0.4559\n",
      "epoch:5,loss:0.3924\n",
      "epoch:5,loss:0.3838\n",
      "accuracy:83.894\n",
      "epoch:6,loss:0.2901\n",
      "epoch:6,loss:0.4023\n",
      "epoch:6,loss:0.3958\n",
      "accuracy:87.088\n",
      "epoch:7,loss:0.1965\n",
      "epoch:7,loss:0.4330\n",
      "epoch:7,loss:0.4754\n",
      "accuracy:89.828\n",
      "epoch:8,loss:0.2278\n",
      "epoch:8,loss:0.1983\n",
      "epoch:8,loss:0.1943\n",
      "accuracy:91.734\n",
      "epoch:9,loss:0.2457\n",
      "epoch:9,loss:0.1989\n",
      "epoch:9,loss:0.1861\n",
      "accuracy:93.286\n",
      "epoch:10,loss:0.1249\n",
      "epoch:10,loss:0.2883\n",
      "epoch:10,loss:0.2747\n",
      "accuracy:94.726\n",
      "epoch:11,loss:0.0701\n",
      "epoch:11,loss:0.1656\n",
      "epoch:11,loss:0.1069\n",
      "accuracy:95.668\n",
      "epoch:12,loss:0.1309\n",
      "epoch:12,loss:0.0364\n",
      "epoch:12,loss:0.1030\n",
      "accuracy:96.686\n",
      "epoch:13,loss:0.1007\n",
      "epoch:13,loss:0.0581\n",
      "epoch:13,loss:0.1134\n",
      "accuracy:96.982\n",
      "epoch:14,loss:0.0353\n",
      "epoch:14,loss:0.0599\n",
      "epoch:14,loss:0.0294\n",
      "accuracy:97.516\n",
      "epoch:15,loss:0.0605\n",
      "epoch:15,loss:0.0265\n",
      "epoch:15,loss:0.0199\n",
      "accuracy:98.112\n"
     ]
    }
   ],
   "source": [
    "new_model = training(model,criterion,optimizer,train_loader,epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1aa46b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T12:03:50.269211Z",
     "iopub.status.busy": "2024-01-12T12:03:50.268460Z",
     "iopub.status.idle": "2024-01-12T12:03:51.395427Z",
     "shell.execute_reply": "2024-01-12T12:03:51.394399Z"
    },
    "papermill": {
     "duration": 1.141215,
     "end_time": "2024-01-12T12:03:51.397634",
     "exception": false,
     "start_time": "2024-01-12T12:03:50.256419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 83.94 %\n"
     ]
    }
   ],
   "source": [
    "evaluation(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb63c3",
   "metadata": {
    "papermill": {
     "duration": 0.010309,
     "end_time": "2024-01-12T12:03:51.418808",
     "exception": false,
     "start_time": "2024-01-12T12:03:51.408499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 21480,
     "sourceId": 27651,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 215.413529,
   "end_time": "2024-01-12T12:03:52.953486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-12T12:00:17.539957",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
